{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bahasa Pemrograman Jumlah Pertanyaan\n",
      "0          javascript           1914032\n",
      "1                java           1616200\n",
      "2                  c#           1365797\n",
      "3                 php           1321732\n",
      "4              python           1303636\n",
      "5             android           1238924\n",
      "6              jquery            972123\n",
      "7                html            865317\n",
      "8                 c++            645905\n",
      "9                 ios            615943\n",
      "10                css            613262\n",
      "11              mysql            580217\n",
      "12                sql            519042\n",
      "13            asp.net            351401\n",
      "14                  r            318494\n",
      "15                  c            317363\n",
      "16             arrays            312844\n",
      "17      ruby-on-rails            312484\n",
      "18            node.js            302578\n",
      "19               .net            290234\n",
      "20        objective-c            288982\n",
      "21               json            277487\n",
      "22         sql-server            274213\n",
      "23          angularjs            259420\n",
      "24              swift            249916\n",
      "25             iphone            220078\n",
      "26              regex            217839\n",
      "27             django            214315\n",
      "28              excel            209830\n",
      "29               ruby            209318\n",
      "30               ajax            204454\n",
      "31         python-3.x            198874\n",
      "32            angular            194233\n",
      "33                xml            188632\n",
      "34        asp.net-mvc            185240\n",
      "35              linux            182442\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Dec  7 12:44:09 2019\n",
    "\n",
    "@author: ian\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataNama = []\n",
    "dataJumlah = []\n",
    "page = requests.get(\"https://stackoverflow.com/tags\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "detail = soup.find_all('div',class_=\"tag-cell\")\n",
    "\n",
    "\n",
    "for x in detail:\n",
    "    nama = x.find('a', class_=\"post-tag\")\n",
    "    jumlah = x.find('span', class_=\"item-multiplier-count\")\n",
    "    dataNama.append(nama.text)\n",
    "    dataJumlah.append(jumlah.text)\n",
    "\n",
    "data = {'Bahasa Pemrograman': dataNama, 'Jumlah Pertanyaan': dataJumlah}\n",
    "hasil = pd.DataFrame(data)\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sedikit Penjelasan\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Dec  7 12:44:09 2019\n",
    "\n",
    "@author: ian\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "```\n",
    "Import bs4 dari BeautifulSoup\n",
    "Import requests\n",
    "Import pandas untuk membuat data frame, kemudian akan dipanggil sebagai pd\n",
    "\n",
    "```python\n",
    "dataNama = []\n",
    "dataJumlah = []\n",
    "```\n",
    "Di atas terdapat dua array yang nantinya sebagai tempat untuk menyimpan data dari hasil scraping\n",
    "\n",
    "```python\n",
    "page = requests.get(\"https://stackoverflow.com/tags\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "detail = soup.find_all('div',class_=\"tag-cell\")\n",
    "```\n",
    "Pertama kita request ke alamat yang akan discraping, pada contoh ini kita akan mencoba melakukan scraping pada website \"https://stackoverflow.com/tags\".\n",
    "\n",
    "Kemudian kita ambil data di dalam tag \"div\" yang memiliki class = \"tag-cell\". Pada syntax ada kata kunci find_all yang berarti akan mengambil [semua] data yang ada pada dalam kurung yang hasilnya disimpan pada variable detail.\n",
    "\n",
    "```python\n",
    "for x in detail:\n",
    "    nama = x.find('a', class_=\"post-tag\")\n",
    "    jumlah = x.find('span', class_=\"item-multiplier-count\")\n",
    "    dataNama.append(nama.text)\n",
    "    dataJumlah.append(jumlah.text)\n",
    "\n",
    "data = {'Bahasa Pemrograman': dataNama, 'Jumlah Pertanyaan': dataJumlah}\n",
    "hasil = pd.DataFrame(data)\n",
    "print(hasil)\n",
    "```\n",
    "\n",
    "Selanjutnya terdapat perulangan atau looping yang berdasarkan sebanyak data yang disimpan pada variable detail.\n",
    "Dalam perulangan kita mengambil nilai yang terdapat dalam tag a dengan class = \"post-tag\" dan tag span dengan class = \"item-multiplier-count\". Dari nilai itu disimpan pada masing - masing array dan ditaruh pada dictionary data yang nantinya diubah menjadi Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
